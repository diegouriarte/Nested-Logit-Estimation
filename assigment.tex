\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Assignment},
            pdfauthor={Diego Uriarte},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Assignment}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Diego Uriarte}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{September 09, 2018}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}

\usepackage{amsmath}

\begin{document}
\maketitle

\hypertarget{conceptual-questions-on-static-demand-and-cost-estimation}{%
\section{Conceptual questions on static demand and cost
estimation}\label{conceptual-questions-on-static-demand-and-cost-estimation}}

\hypertarget{explain-in-words-why-price-is-endogenous-in-berrys-framework-in-discrete-choice-models}{%
\subsection{Explain in words why price is endogenous in Berry's
framework in discrete choice
models?}\label{explain-in-words-why-price-is-endogenous-in-berrys-framework-in-discrete-choice-models}}

The price is endogenous because of the unobservable product
characteristics (\(\xi_j\)). The consumer does observe these
characteristics but not the econometrician (there are not in the
dataset). The endogeneity occurs because the unobservable
characteristics of the cars (that the consumers do observe) is obviously
correlated with the price. For that reason, in the equation:

\[ \ln(s_j) - \ln(s_0) = x_j \times \beta - \alpha \times p_j + \xi_j\]
A higher \(\xi_j\) will cause a higher \(p_j\) (because firms are in a
Bertrand price competition), all else equal.

\hypertarget{explain-in-words-why-within-group-share-is-endogenous-in-discrete-choice-models}{%
\subsection{Explain in words why within-group share is endogenous in
discrete choice
models?}\label{explain-in-words-why-within-group-share-is-endogenous-in-discrete-choice-models}}

The within-group is endogenous because is correlated with the
unobservable product characteristics (\(\xi_j\)). For instance, if the
share of Mercedes Benz automobiles goes down (maybe because there is an
increase in their prices), we would expect that the share of BMW cars
goes up by much more than the share of Nissan cars. This would be
because both Mercedes and BMW share characteristics that appeal to the
same costumers.

\hypertarget{derive-marginal-costs-for-single-product-firms-for-berrys-nested-logit-model-given-data-and-estimated-parameters.}{%
\subsection{Derive marginal costs for single-product firms for Berry's
nested logit model, given data and estimated
parameters.}\label{derive-marginal-costs-for-single-product-firms-for-berrys-nested-logit-model-given-data-and-estimated-parameters.}}

First, profit for firm j are given by:

\[\pi_j(\mathbf{p}, z, \xi , \omega_j, \theta) = p_j M s_j(x, \xi, p, \theta_d) - C_j(q_j, w_j, \omega_j, \gamma)\]
Where, p are prices, x, w observed characteristics, \(\xi\) and
\(\omega\) unobserved characteristics, \(\theta_d\) demand parameter, M
is total market size.

Since firms are price setters, and if we assume that there is an
interior equilibrium, the FOC are:

\[p_j = c_j + s_j/|\partial s_j/ \partial p_j| \] Also, using the chain
rule
(\(\frac{\partial s_j}{\partial \delta_j}\frac{\partial \delta_j}{\partial p_j} = \frac{\partial s_j}{\partial p_j}\)),
and using the definition of \(\delta_j\) to differentiate
\(\frac{\partial \delta_j}{\partial p_j} = -\alpha\) we get:

\[- \alpha \frac{\partial s_j}{\partial \delta_j} = \frac{\partial s_j}{\partial p_j} \]

Also, we assume that the marginal cost is linear in the unobservable
cost term \(\omega_j\), we get
\(c_j = \bar{c}(q_j, w_j, \gamma) + \omega_j\). Replacing in the FOC:

\[ p_j = \bar{c_j} + \frac{1}{\alpha}[s_j/|\partial s_j/ \partial \delta_j|] + \omega_j \]
Using the market share equation for the logit model, we get:

\[ \partial \mathcal{s}_j/ \partial \delta_j = \frac{1}{1-\sigma}s_j[1 - \sigma \bar{s_{j/g}}-(1-\sigma)s_j]\]
Finally, replacing in the previous expression:

\[ 
p_j = \bar{c_j} + \frac{1-\sigma}{\alpha}/[1 - \sigma \bar{s_{j/g}}-(1-\sigma)s_j] + \omega_j
\]

Since the parameters have been estimated, we can determine average
marginal cost from the previous expression.

\hypertarget{what-are-two-useful-source-of-instruments-for-discrete-choice-models-explain.}{%
\subsection{What are two useful source of instruments for discrete
choice models?
Explain.}\label{what-are-two-useful-source-of-instruments-for-discrete-choice-models-explain.}}

One possibility is to use price variation across cities or regions as
cost shifters. They are a valid instrument if the marginal costs are
correlated across cities, but not the unobservable product
characteristics (\(\xi_j\)). That is to say that the price of a good in
city j is correlated with the marginal cost in city j, that is
correlated with the marginal cost in city i. But \(\xi_i\) and \(\xi_j\)
are not correlated.

For the automobile sector, changes in fuel prices generate cost
variation. The consumer is interested in how long can she travel with
1\$ of fuel (miles per dollar), but for the car maker, increase the
miles per gallon for a given model is costly. For that reason, fuel
prices variation can be used as cost shifter, but they may not be that
strong.

\hypertarget{sec:question5}{%
\subsection{What are two reasons to estimate the supply side models
along with the demand side of discrete choice models?
Explain.}\label{sec:question5}}

Only estimating the demand side is consistent with the endogeneity of
prices and with equilibrium results, however, by adding the supply side
we can get better or more precise estimates of the parameters. Another
reason to incorporate supply side models and solve for the equilibrium
is that we can test with type of competitive model fits best the data.
As Miller and Weinberg (2017) used this approach to reject the
hypothesis that there was a Nash-Bertrand equilibrium between two
brewing company after their merge.

\hypertarget{what-are-the-advantages-of-using-a-random-coefficients-model-a-la-blp-instead-of-a-nested-logit-model}{%
\subsection{What are the advantages of using a random coefficients
model, Ã  la BLP, instead of a nested logit
model?}\label{what-are-the-advantages-of-using-a-random-coefficients-model-a-la-blp-instead-of-a-nested-logit-model}}

IV estimator for the nested logit model is just a special case of the
BLP model, where \(\xi_j\) is linear in the parameters. The advantage of
BLP is that it allows for non-linear relation between \(\xi_j\) and the
parameters, by recovering the function numerically. Another advantage is
that BLP added equilibrium behavior to the models, and as it was
discussed in the previous question, it can improve the accuracy of the
parameters and allows us to test for market behavior.

\hypertarget{computational-questions-on-static-demand-and-cost-estimation-40-points}{%
\section{Computational questions on static demand and cost estimation
(40
points)}\label{computational-questions-on-static-demand-and-cost-estimation-40-points}}

\hypertarget{collapse-the-data-to-the-product-market-level-and-drop-the-outside-good-for-each-market-as-observations-creating-an-outside-good-share-variable-for-each-inside-good-choice.-report-summary-statistics-on-market-shares-and-outside-good-share-by-plan-number.-report-the-number-of-observations.}{%
\subsection{Collapse the data to the product / market level and drop the
outside good for each market as observations, creating an ``outside good
share'' variable for each inside good choice. Report summary statistics
on market shares and outside good share by plan number. Report the
number of
observations.}\label{collapse-the-data-to-the-product-market-level-and-drop-the-outside-good-for-each-market-as-observations-creating-an-outside-good-share-variable-for-each-inside-good-choice.-report-summary-statistics-on-market-shares-and-outside-good-share-by-plan-number.-report-the-number-of-observations.}}

First, we explore the dataset

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data <-}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{(data)}
\KeywordTok{str}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Classes 'tbl_df', 'tbl' and 'data.frame':    381768 obs. of  11 variables:
##  $ individual   : int  1 1 1 1 1 2 2 2 2 2 ...
##  $ market       : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ plan         : int  0 1 2 3 4 0 1 2 3 4 ...
##  $ num_plans    : int  5 5 5 5 5 5 5 5 5 5 ...
##  $ choice       : int  0 1 0 0 0 0 0 1 0 0 ...
##  $ price        : num  0 1.094 1.319 0.876 0.908 ...
##  $ xsi          : num  0 0.6312 0.9206 0.0309 0.0125 ...
##  $ x_constant   : int  0 1 1 1 1 0 1 1 1 1 ...
##  $ x_coinsurance: num  0 0.4596 0.4411 0.4561 0.0803 ...
##  $ x_deductible : num  0 0.1749 0.3555 0.0952 0.1625 ...
##  $ x_oopmax     : num  0 0.0973 0.3058 0.089 0.4978 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 11
##   individual market  plan num_plans choice price    xsi x_constant
##        <int>  <int> <int>     <int>  <int> <dbl>  <dbl>      <int>
## 1          1      1     0         5      0 0     0               0
## 2          1      1     1         5      1 1.09  0.631           1
## 3          1      1     2         5      0 1.32  0.921           1
## 4          1      1     3         5      0 0.876 0.0309          1
## 5          1      1     4         5      0 0.908 0.0125          1
## 6          2      1     0         5      0 0     0               0
## # ... with 3 more variables: x_coinsurance <dbl>, x_deductible <dbl>,
## #   x_oopmax <dbl>
\end{verbatim}

There are 89801 persons in the dataset, 100 markets, each with different
plans We are given information about the plan chose by each individual
(\texttt{choice} variable), as well as the price, and the observable
characteristic in each plan
(\texttt{x\_constant,\ x\_coinsurance,\ x\_deductible,\ x\_oopmax}). It
is important to note that plan x in market i is not the same as plan x
in market j. The value \texttt{xsi} represents the unobservable
characteristics, and as such, they will only be used at the ended as a
benchmark for our regression results.

We are asked to collapse the data to the market level. First, we will
keep only the row corresponding to the choice made by the individual.

We create a table with the outside share for each market (there should
be 100 values)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{freq_market <-}\StringTok{ }\NormalTok{data }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(choice }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(market, plan) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{freq =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n)) }

\NormalTok{outside_market <-}\StringTok{ }\NormalTok{freq_market }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(plan }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We transform the original data, dropping the outside good and only
keeping the product choose by each individual in given market:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(choice }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{left_join}\NormalTok{(outside_market }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(market, freq), }\DataTypeTok{by =} \StringTok{"market"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 89,801 x 12
##    individual market  plan num_plans choice price   xsi x_constant
##         <int>  <int> <int>     <int>  <int> <dbl> <dbl>      <int>
##  1          1      1     1         5      1  1.09 0.631          1
##  2          2      1     2         5      1  1.32 0.921          1
##  3          3      1     2         5      1  1.32 0.921          1
##  4          4      1     2         5      1  1.32 0.921          1
##  5          5      1     0         5      1  0    0              0
##  6          6      1     2         5      1  1.32 0.921          1
##  7          7      1     2         5      1  1.32 0.921          1
##  8          8      1     2         5      1  1.32 0.921          1
##  9          9      1     2         5      1  1.32 0.921          1
## 10         10      1     2         5      1  1.32 0.921          1
## # ... with 89,791 more rows, and 4 more variables: x_coinsurance <dbl>,
## #   x_deductible <dbl>, x_oopmax <dbl>, freq <dbl>
\end{verbatim}

Since there is information not needed, we drop them from the table and
the change the \texttt{freq} variable to \texttt{s\_0} (outside option):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data_with_s0 <-}\StringTok{ }\NormalTok{data }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(choice }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{left_join}\NormalTok{(outside_market }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(market, freq), }\DataTypeTok{by =} \StringTok{"market"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(individual}\OperatorTok{:}\NormalTok{plan, }\DataTypeTok{s_0 =}\NormalTok{ freq, price}\OperatorTok{:}\NormalTok{x_oopmax)}

\NormalTok{data_with_s0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 89,801 x 10
##    individual market  plan   s_0 price   xsi x_constant x_coinsurance
##         <int>  <int> <int> <dbl> <dbl> <dbl>      <int>         <dbl>
##  1          1      1     1 0.352  1.09 0.631          1         0.460
##  2          2      1     2 0.352  1.32 0.921          1         0.441
##  3          3      1     2 0.352  1.32 0.921          1         0.441
##  4          4      1     2 0.352  1.32 0.921          1         0.441
##  5          5      1     0 0.352  0    0              0         0    
##  6          6      1     2 0.352  1.32 0.921          1         0.441
##  7          7      1     2 0.352  1.32 0.921          1         0.441
##  8          8      1     2 0.352  1.32 0.921          1         0.441
##  9          9      1     2 0.352  1.32 0.921          1         0.441
## 10         10      1     2 0.352  1.32 0.921          1         0.441
## # ... with 89,791 more rows, and 2 more variables: x_deductible <dbl>,
## #   x_oopmax <dbl>
\end{verbatim}

Then, we collapse the data by calculating the shares of each product for
each market.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(choice }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(market, plan) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{freq =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(plan }\OperatorTok{!=}\StringTok{ }\DecValTok{0}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 325 x 4
## # Groups:   market [100]
##    market  plan     n   freq
##     <int> <int> <int>  <dbl>
##  1      1     1   170 0.183 
##  2      1     2   278 0.300 
##  3      1     3    63 0.0679
##  4      1     4    90 0.0970
##  5      2     1    97 0.101 
##  6      2     2    16 0.0166
##  7      2     3   254 0.264 
##  8      2     4   246 0.256 
##  9      2     5    13 0.0135
## 10      3     1   214 0.242 
## # ... with 315 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{collapsed_data <-}\StringTok{ }\NormalTok{data_with_s0  }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(market, plan) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(plan }\OperatorTok{!=}\StringTok{ }\DecValTok{0}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{s_0 =} \KeywordTok{mean}\NormalTok{(s_}\DecValTok{0}\NormalTok{), }
            \DataTypeTok{price =} \KeywordTok{mean}\NormalTok{(price), }
            \DataTypeTok{xsi =} \KeywordTok{mean}\NormalTok{(xsi), }
            \DataTypeTok{x_constant =} \KeywordTok{mean}\NormalTok{(x_constant),}
            \DataTypeTok{x_coinsurance =} \KeywordTok{mean}\NormalTok{(x_coinsurance),}
            \DataTypeTok{x_deductible =} \KeywordTok{mean}\NormalTok{(x_deductible),}
            \DataTypeTok{x_oopmax =} \KeywordTok{mean}\NormalTok{(x_oopmax)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{left_join}\NormalTok{(freq_market }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(market, plan, }\DataTypeTok{s_j =}\NormalTok{ freq), }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"market"}\NormalTok{,}\StringTok{"plan"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{s_j_given_g =}\NormalTok{ s_j }\OperatorTok{/}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{s_}\DecValTok{0}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(market}\OperatorTok{:}\NormalTok{s_}\DecValTok{0}\NormalTok{, s_j, s_j_given_g, price}\OperatorTok{:}\NormalTok{x_oopmax)}
  
\NormalTok{collapsed_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 325 x 11
## # Groups:   market [100]
##    market  plan   s_0    s_j s_j_given_g price     xsi x_constant
##     <int> <int> <dbl>  <dbl>       <dbl> <dbl>   <dbl>      <dbl>
##  1      1     1 0.352 0.183       0.283  1.09   0.631           1
##  2      1     2 0.352 0.300       0.463  1.32   0.921           1
##  3      1     3 0.352 0.0679      0.105  0.876  0.0309          1
##  4      1     4 0.352 0.0970      0.150  0.908  0.0125          1
##  5      2     1 0.349 0.101       0.155  0.932  0.237           1
##  6      2     2 0.349 0.0166      0.0256 0.814 -0.650           1
##  7      2     3 0.349 0.264       0.406  1.21   0.681           1
##  8      2     4 0.349 0.256       0.393  1.23   0.657           1
##  9      2     5 0.349 0.0135      0.0208 0.813 -0.738           1
## 10      3     1 0.549 0.242       0.536  1.34   0.0325          1
## # ... with 315 more rows, and 3 more variables: x_coinsurance <dbl>,
## #   x_deductible <dbl>, x_oopmax <dbl>
\end{verbatim}

Now, we find the summary statistic by plan number:

\begin{tabular}{l|l|l|l|l|l}
\hline
 & plan: 1 (N = 100) & plan: 2 (N = 100) & plan: 3 (N = 66) & plan: 4 (N = 39) & plan: 5 (N = 20)\\
\hline
\bf{price} & ~ & ~ & ~ & ~ & ~\\
\hline
~~ min & 0.812888 & 0.814086 & 0.805460 & 0.813620 & 0.807153\\
\hline
~~ max & 2.13393 & 2.47220 & 1.83560 & 1.29913 & 1.47126\\
\hline
~~ mean (sd) & 1.19 $\pm$ 0.29 & 1.19 $\pm$ 0.33 & 1.08 $\pm$ 0.25 & 0.96 $\pm$ 0.13 & 0.95 $\pm$ 0.17\\
\hline
\bf{xsi} & ~ & ~ & ~ & ~ & ~\\
\hline
~~ min & -1.059690 & -1.048210 & -1.054930 & -1.114970 & -0.954659\\
\hline
~~ max & 1.394570 & 1.413610 & 1.462110 & 0.708806 & 0.688833\\
\hline
~~ mean (sd) & 0.05 $\pm$ 0.41 & 0.02 $\pm$ 0.51 & -0.02 $\pm$ 0.52 & -0.12 $\pm$ 0.42 & -0.13 $\pm$ 0.47\\
\hline
\bf{x\_coinsurance} & ~ & ~ & ~ & ~ & ~\\
\hline
~~ min & 0.812888 & 0.814086 & 0.805460 & 0.813620 & 0.807153\\
\hline
~~ max & 2.13393 & 2.47220 & 1.83560 & 1.29913 & 1.47126\\
\hline
~~ mean (sd) & 1.19 $\pm$ 0.29 & 1.19 $\pm$ 0.33 & 1.08 $\pm$ 0.25 & 0.96 $\pm$ 0.13 & 0.95 $\pm$ 0.17\\
\hline
\bf{x\_deductible} & ~ & ~ & ~ & ~ & ~\\
\hline
~~ min & 0.812888 & 0.814086 & 0.805460 & 0.813620 & 0.807153\\
\hline
~~ max & 2.13393 & 2.47220 & 1.83560 & 1.29913 & 1.47126\\
\hline
~~ mean (sd) & 1.19 $\pm$ 0.29 & 1.19 $\pm$ 0.33 & 1.08 $\pm$ 0.25 & 0.96 $\pm$ 0.13 & 0.95 $\pm$ 0.17\\
\hline
\bf{x\_oopmax} & ~ & ~ & ~ & ~ & ~\\
\hline
~~ min & 0.812888 & 0.814086 & 0.805460 & 0.813620 & 0.807153\\
\hline
~~ max & 2.13393 & 2.47220 & 1.83560 & 1.29913 & 1.47126\\
\hline
~~ mean (sd) & 1.19 $\pm$ 0.29 & 1.19 $\pm$ 0.33 & 1.08 $\pm$ 0.25 & 0.96 $\pm$ 0.13 & 0.95 $\pm$ 0.17\\
\hline
\end{tabular}

\hypertarget{construct-as-instruments-the-within-group-sum-of-every-characteristic.-report-summary-statistics-on-your-instruments-with-the-stata-summarize-command-or-analog-in-the-software-that-you-use}{%
\subsection{Construct as instruments the within-group sum of every
characteristic. Report summary statistics on your instruments, with the
Stata ``summarize'' command or analog in the software that you
use}\label{construct-as-instruments-the-within-group-sum-of-every-characteristic.-report-summary-statistics-on-your-instruments-with-the-stata-summarize-command-or-analog-in-the-software-that-you-use}}

First, we add a column to the table with the within-group sum of every
characteristic (\texttt{z1,\ z2,\ z3}). However, following Barry, we
will also try with the within-group sum of the characteristics without
the plan \texttt{j}. We call these three instruments
(\texttt{z11.\ z22.\ z33}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data_with_instruments <-}\StringTok{ }\NormalTok{collapsed_data }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(market) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{z1 =} \KeywordTok{sum}\NormalTok{(x_coinsurance), }\DataTypeTok{z2 =} \KeywordTok{sum}\NormalTok{(x_deductible), }\DataTypeTok{z3 =} \KeywordTok{sum}\NormalTok{(x_oopmax)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{right_join}\NormalTok{(collapsed_data, }\DataTypeTok{by =} \StringTok{"market"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(market, plan}\OperatorTok{:}\NormalTok{x_oopmax, z1}\OperatorTok{:}\NormalTok{z3) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{z11 =}\NormalTok{ z1 }\OperatorTok{-}\StringTok{ }\NormalTok{x_coinsurance, }\DataTypeTok{z22 =}\NormalTok{ z2 }\OperatorTok{-}\StringTok{ }\NormalTok{x_deductible, }\DataTypeTok{z33 =}\NormalTok{ z3 }\OperatorTok{-}\StringTok{ }\NormalTok{x_deductible)}

\NormalTok{data_with_instruments }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(z1, z2, z3, z11, z22, z33) }\OperatorTok{%>%}\StringTok{ }\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        z1                z2               z3               z11          
##  Min.   :0.06864   Min.   :0.2497   Min.   :0.09086   Min.   :0.002513  
##  1st Qu.:0.66646   1st Qu.:0.6735   1st Qu.:0.63388   1st Qu.:0.415790  
##  Median :0.92851   Median :0.9460   Median :0.89035   Median :0.678881  
##  Mean   :0.94628   Mean   :0.9877   Mean   :0.91782   Mean   :0.685327  
##  3rd Qu.:1.23344   3rd Qu.:1.2356   3rd Qu.:1.30162   3rd Qu.:0.976185  
##  Max.   :1.56273   Max.   :1.9355   Max.   :1.75793   Max.   :1.507379  
##       z22                z33         
##  Min.   :0.003761   Min.   :-0.2395  
##  1st Qu.:0.417792   1st Qu.: 0.3585  
##  Median :0.692470   Median : 0.6365  
##  Mean   :0.716415   Mean   : 0.6465  
##  3rd Qu.:0.993354   3rd Qu.: 0.9571  
##  Max.   :1.754211   Max.   : 1.6024
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{our_summary2 <-}\StringTok{ }
\StringTok{  }\KeywordTok{with}\NormalTok{(data_with_instruments,}
       \KeywordTok{list}\NormalTok{(}\StringTok{"z1"}\NormalTok{ =}\StringTok{ }\KeywordTok{tab_summary}\NormalTok{(z1),}
            \StringTok{"z2"}\NormalTok{ =}\StringTok{ }\KeywordTok{tab_summary}\NormalTok{(z2),}
            \StringTok{"z3"}\NormalTok{ =}\StringTok{ }\KeywordTok{tab_summary}\NormalTok{(z3))}
\NormalTok{  )}
  

\NormalTok{whole_table <-}\StringTok{ }\KeywordTok{summary_table}\NormalTok{(data_with_instruments, our_summary2)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l}
\hline
Summary Statistics & N = 325\\
\hline
\bf{z1} & ~\\
\hline
~~ min & 0.0686351\\
\hline
~~ median (IQR) & 0.93 (0.67, 1.23)\\
\hline
~~ mean (sd) & 0.95 $\pm$ 0.36\\
\hline
~~ max & 1.562735\\
\hline
\bf{z2} & ~\\
\hline
~~ min & 0.2497498\\
\hline
~~ median (IQR) & 0.95 (0.67, 1.24)\\
\hline
~~ mean (sd) & 0.99 $\pm$ 0.41\\
\hline
~~ max & 1.935549\\
\hline
\bf{z3} & ~\\
\hline
~~ min & 0.09085784\\
\hline
~~ median (IQR) & 0.89 (0.63, 1.30)\\
\hline
~~ mean (sd) & 0.92 $\pm$ 0.39\\
\hline
~~ max & 1.75793\\
\hline
\end{tabular}

\hypertarget{estimate-a-nested-logit-model-using-berrys-method-not-instrumenting-for-within-group-share-or-price.-report-your-results.}{%
\subsection{Estimate a nested logit model using Berry's method, not
instrumenting for within-group share or price. Report your
results.}\label{estimate-a-nested-logit-model-using-berrys-method-not-instrumenting-for-within-group-share-or-price.-report-your-results.}}

Now, we estimate the nested logit model. The model is as follows:

\[
\ln(s_j) - \ln(s_0) = \beta_0 + \beta_1 x_{coinsurance} + \beta_2 x_{deductible} + \beta_3 x_{oopmax} - \alpha p_j + \sigma \ln(s_{j/g}) + \xi_j
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{transformed_data <-}\StringTok{ }\NormalTok{data_with_instruments }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ln_sj_minus_s0 =} \KeywordTok{log}\NormalTok{(s_j) }\OperatorTok{-}\StringTok{ }\KeywordTok{log}\NormalTok{(s_}\DecValTok{0}\NormalTok{), }
         \DataTypeTok{ln_sj_g =} \KeywordTok{log}\NormalTok{(s_j_given_g)) }
\NormalTok{reg1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ transformed_data, }\DataTypeTok{formula =}\NormalTok{ ln_sj_minus_s0 }\OperatorTok{~}\StringTok{ }\NormalTok{x_coinsurance }\OperatorTok{+}\StringTok{ }\NormalTok{x_deductible }\OperatorTok{+}\StringTok{ }\NormalTok{x_oopmax }\OperatorTok{+}\StringTok{ }\NormalTok{price }\OperatorTok{+}\StringTok{ }\NormalTok{ln_sj_g)}
\KeywordTok{summary}\NormalTok{(reg1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = ln_sj_minus_s0 ~ x_coinsurance + x_deductible + 
##     x_oopmax + price + ln_sj_g, data = transformed_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.98191 -0.25049  0.02532  0.24990  0.81439 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   -0.11916    0.17393  -0.685   0.4938    
## x_coinsurance -0.26490    0.14029  -1.888   0.0599 .  
## x_deductible  -0.20614    0.13369  -1.542   0.1241    
## x_oopmax       0.20636    0.13156   1.569   0.1177    
## price          0.10443    0.10094   1.035   0.3016    
## ln_sj_g        0.80387    0.03125  25.727   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3388 on 319 degrees of freedom
## Multiple R-squared:  0.8435, Adjusted R-squared:  0.8411 
## F-statistic:   344 on 5 and 319 DF,  p-value: < 2.2e-16
\end{verbatim}

\hypertarget{estimate-a-nested-logit-model-using-berrys-method-instrumenting-for-within-group-share-but-not-price.-report-your-results.}{%
\subsection{Estimate a nested logit model using Berry's method,
instrumenting for within-group share but not price. Report your
results.}\label{estimate-a-nested-logit-model-using-berrys-method-instrumenting-for-within-group-share-but-not-price.-report-your-results.}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg2 <-}\StringTok{ }\KeywordTok{ivreg}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ transformed_data, }
      \DataTypeTok{formula =}\NormalTok{ ln_sj_minus_s0 }\OperatorTok{~}\StringTok{ }\NormalTok{x_coinsurance }\OperatorTok{+}\StringTok{ }\NormalTok{x_deductible }\OperatorTok{+}\StringTok{ }\NormalTok{x_oopmax }\OperatorTok{+}\StringTok{ }\NormalTok{price }\OperatorTok{+}\StringTok{ }\NormalTok{ln_sj_g }\OperatorTok{|}\StringTok{ }\NormalTok{. }\OperatorTok{-}\StringTok{ }\NormalTok{ln_sj_g }\OperatorTok{+}\StringTok{ }\NormalTok{z1 }\OperatorTok{+}\StringTok{ }\NormalTok{z2 }\OperatorTok{+}\StringTok{ }\NormalTok{z3)}

\KeywordTok{summary}\NormalTok{(reg2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## ivreg(formula = ln_sj_minus_s0 ~ x_coinsurance + x_deductible + 
##     x_oopmax + price + ln_sj_g | . - ln_sj_g + z1 + z2 + z3, 
##     data = transformed_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0257 -0.2556  0.1309  0.4060  1.1356 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   -3.74824    0.87511  -4.283 2.44e-05 ***
## x_coinsurance -0.02080    0.25583  -0.081   0.9352    
## x_deductible  -0.28211    0.23870  -1.182   0.2381    
## x_oopmax       0.62764    0.25283   2.482   0.0136 *  
## price          2.11343    0.48744   4.336 1.95e-05 ***
## ln_sj_g       -0.01853    0.19364  -0.096   0.9238    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.6033 on 319 degrees of freedom
## Multiple R-Squared: 0.5038,  Adjusted R-squared: 0.496 
## Wald test: 66.71 on 5 and 319 DF,  p-value: < 2.2e-16
\end{verbatim}

\hypertarget{estimate-a-nested-logit-model-using-berrys-method-instrumenting-for-within-group-share-and-price.-report-your-results.-does-it-appear-that-price-was-endogenous-how-are-you-making-this-judgment}{%
\subsection{Estimate a nested logit model using Berry's method,
instrumenting for within-group share and price. Report your results.
Does it appear that price was endogenous? How are you making this
judgment?}\label{estimate-a-nested-logit-model-using-berrys-method-instrumenting-for-within-group-share-and-price.-report-your-results.-does-it-appear-that-price-was-endogenous-how-are-you-making-this-judgment}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg3 <-}\StringTok{ }\KeywordTok{ivreg}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ transformed_data, }
      \DataTypeTok{formula =}\NormalTok{ ln_sj_minus_s0 }\OperatorTok{~}\StringTok{ }\NormalTok{x_coinsurance }\OperatorTok{+}\StringTok{ }\NormalTok{x_deductible }\OperatorTok{+}\StringTok{ }\NormalTok{x_oopmax }\OperatorTok{+}\StringTok{ }\NormalTok{price }\OperatorTok{+}\StringTok{ }\NormalTok{ln_sj_g }\OperatorTok{|}\StringTok{ }\NormalTok{. }\OperatorTok{-}\StringTok{ }\NormalTok{price }\OperatorTok{-}\StringTok{ }\NormalTok{ln_sj_g }\OperatorTok{+}\StringTok{ }\NormalTok{z1 }\OperatorTok{+}\StringTok{ }\NormalTok{z2 }\OperatorTok{+}\StringTok{ }\NormalTok{z3)}

\KeywordTok{summary}\NormalTok{(reg3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## ivreg(formula = ln_sj_minus_s0 ~ x_coinsurance + x_deductible + 
##     x_oopmax + price + ln_sj_g | . - price - ln_sj_g + z1 + z2 + 
##     z3, data = transformed_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.11665 -0.35187 -0.08585  0.26870  2.65404 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)   
## (Intercept)    2.54694    1.83910   1.385  0.16706   
## x_coinsurance -0.95821    0.34676  -2.763  0.00605 **
## x_deductible  -0.49901    0.23739  -2.102  0.03633 * 
## x_oopmax       0.06652    0.28436   0.234  0.81518   
## price         -1.83602    1.12769  -1.628  0.10449   
## ln_sj_g        0.93102    0.30934   3.010  0.00282 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.5829 on 319 degrees of freedom
## Multiple R-Squared: 0.5368,  Adjusted R-squared: 0.5295 
## Wald test: 12.43 on 5 and 319 DF,  p-value: 4.953e-11
\end{verbatim}

We observe that when we don't use instruments for price nor withing
group share, the price coefficient is positive (0.1044329) which would
indicate that an increase in price increases the market share of the
plan. Controlling for within group share does not disappear this effect
since the price coefficient for the second regression is 2.1134273.
However, controlling for price does make the price coefficient negative,
which intuitively makes sense since from the model we are quite sure
that price is correlated with \(\xi_j\).

In addition, using as instruments for each plan \texttt{k} the within
sum characteristic for values different than \texttt{k}
(\(z_{11} = \sum_{i \neq k } x_{i}\)), provides the same estimates:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg3 <-}\StringTok{ }\KeywordTok{ivreg}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ transformed_data, }
      \DataTypeTok{formula =}\NormalTok{ ln_sj_minus_s0 }\OperatorTok{~}\StringTok{ }\NormalTok{x_coinsurance }\OperatorTok{+}\StringTok{ }\NormalTok{x_deductible }\OperatorTok{+}\StringTok{ }\NormalTok{x_oopmax }\OperatorTok{+}\StringTok{ }\NormalTok{price }\OperatorTok{+}\StringTok{ }\NormalTok{ln_sj_g }\OperatorTok{|}\StringTok{ }\NormalTok{. }\OperatorTok{-}\StringTok{ }\NormalTok{price }\OperatorTok{-}\StringTok{ }\NormalTok{ln_sj_g }\OperatorTok{+}\StringTok{ }\NormalTok{z11 }\OperatorTok{+}\StringTok{ }\NormalTok{z22 }\OperatorTok{+}\StringTok{ }\NormalTok{z33)}

\KeywordTok{summary}\NormalTok{(reg3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## ivreg(formula = ln_sj_minus_s0 ~ x_coinsurance + x_deductible + 
##     x_oopmax + price + ln_sj_g | . - price - ln_sj_g + z11 + 
##     z22 + z33, data = transformed_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.11665 -0.35187 -0.08585  0.26870  2.65404 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)   
## (Intercept)    2.54694    1.83910   1.385  0.16706   
## x_coinsurance -0.95821    0.34676  -2.763  0.00605 **
## x_deductible  -0.49901    0.23739  -2.102  0.03633 * 
## x_oopmax       0.06652    0.28436   0.234  0.81518   
## price         -1.83602    1.12769  -1.628  0.10449   
## ln_sj_g        0.93102    0.30934   3.010  0.00282 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.5829 on 319 degrees of freedom
## Multiple R-Squared: 0.5368,  Adjusted R-squared: 0.5295 
## Wald test: 12.43 on 5 and 319 DF,  p-value: 4.953e-11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{transformed_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 325 x 19
##    market  plan   s_0    s_j s_j_given_g price     xsi x_constant
##     <int> <int> <dbl>  <dbl>       <dbl> <dbl>   <dbl>      <dbl>
##  1      1     1 0.352 0.183       0.283  1.09   0.631           1
##  2      1     2 0.352 0.300       0.463  1.32   0.921           1
##  3      1     3 0.352 0.0679      0.105  0.876  0.0309          1
##  4      1     4 0.352 0.0970      0.150  0.908  0.0125          1
##  5      2     1 0.349 0.101       0.155  0.932  0.237           1
##  6      2     2 0.349 0.0166      0.0256 0.814 -0.650           1
##  7      2     3 0.349 0.264       0.406  1.21   0.681           1
##  8      2     4 0.349 0.256       0.393  1.23   0.657           1
##  9      2     5 0.349 0.0135      0.0208 0.813 -0.738           1
## 10      3     1 0.549 0.242       0.536  1.34   0.0325          1
## # ... with 315 more rows, and 11 more variables: x_coinsurance <dbl>,
## #   x_deductible <dbl>, x_oopmax <dbl>, z1 <dbl>, z2 <dbl>, z3 <dbl>,
## #   z11 <dbl>, z22 <dbl>, z33 <dbl>, ln_sj_minus_s0 <dbl>, ln_sj_g <dbl>
\end{verbatim}

\hypertarget{conceptual-questions-on-applications-of-discrete-choice-models-to-antitrust-20-points}{%
\section{Conceptual questions on applications of discrete choice models
to antitrust (20
points)}\label{conceptual-questions-on-applications-of-discrete-choice-models-to-antitrust-20-points}}

\hypertarget{how-did-prof.nevo-argue-that-the-nested-logit-model-was-a-useful-demand-model-in-the-aetnahumana-merger-case-please-read-the-judges-decision-in-this-case-that-is-on-the-syllabus.}{%
\subsection{How did Prof.~Nevo argue that the nested logit model was a
useful demand model, in the Aetna/Humana merger case? (Please read the
judge's decision in this case that is on the
syllabus.)}\label{how-did-prof.nevo-argue-that-the-nested-logit-model-was-a-useful-demand-model-in-the-aetnahumana-merger-case-please-read-the-judges-decision-in-this-case-that-is-on-the-syllabus.}}

Prof.~Nevo used the CMS data on Medicare Advantage plan enrollments,
that also included seniors who chose Original Medicare Options. The
nested logit was useful in this context because it allows us to test
\emph{whether, an to what degree, a senior might prefer ``a Medicare
Advantage plan because it is a Medicare Advantage plan''} (United States
District Court for the District of Columbia (2017)). The key parameter
in the model is the nesting parameter, that indicates the strength of
this preference and it can have values between 0 and 1.

Nevo found that 70\% of users of one of the Medicare Advantage plans
would change to another Medicare Advantage plan (nesting parameter of
0.65). Nevo considered this to be an conservative estimated since the
data showed that around 80\% of seniors change a Medicare Advantage Plan
of another Medicare Advantage Plan. Using this model, we was able to
prove that an hypothetical profit-maximizing monopolist could profitably
increase prices in any county.

One turning point for the judge to accept Nevo's econometric evidence
was that he used the defendant nesting parameters (that were much lower
that his) and the lowest parameter he could find the literature, and
still found that the Medicare Advantage passed the SSNIP test of 5\% or
10\%, that is, an hypothetical monopolist in that market could
profitably increase prices in more than 5\%.

\hypertarget{how-would-you-would-perform-a-hypothetical-monopolist-test-for-your-estimated-model-of-insurance-demand-explain-with-words-and-equations.}{%
\subsection{How would you would perform a hypothetical monopolist test
for your estimated model of insurance demand? Explain with words and
equations.}\label{how-would-you-would-perform-a-hypothetical-monopolist-test-for-your-estimated-model-of-insurance-demand-explain-with-words-and-equations.}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-miller2017}{}%
Miller, Nathan H, and Matthew C Weinberg. 2017. ``Understanding the
Price Effects of the Millercoors Joint Venture.'' \emph{Econometrica} 85
(6). Wiley Online Library: 1763--91.

\leavevmode\hypertarget{ref-aetna}{}%
United States District Court for the District of Columbia. 2017.
``United States et al. v. AETNA INC et al.''
\url{https://www.justice.gov/opa/press-release/file/930361/download}.


\end{document}
